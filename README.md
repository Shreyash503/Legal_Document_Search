ğŸ“˜ Legal Document Search Assistant (AI-Powered RAG System)

An intelligent AI-based legal document question-answering system that allows users to:

Upload any legal or policy PDF

Automatically process the PDF using RAG (Retrieval-Augmented Generation)

Ask natural language questions

Receive precise, 2-line answers generated by Groqâ€™s Llama 3.1 model

This project uses Flask, LangChain, ChromaDB, HuggingFace embeddings, and a modern animated frontend.

ğŸš€ Features
ğŸ§¾ PDF Upload

Upload any type of legal or academic document such as:

Court judgments

Acts & Rules

Government policies

Budget speeches

Research papers

âš¡ AI-Powered Answers

Ask any question; the system performs semantic search and responds intelligently.

ğŸ§  RAG Pipeline

PDF â†’ text extraction

Text â†’ chunks (RecursiveCharacterTextSplitter)

Chunks â†’ embeddings (HuggingFace)

Stored in Chroma Vector DB

Relevant chunks â†’ LLM (Groq Llama-3.1)

2-line answer generated

ğŸ¨ Modern Frontend

3D glassmorphism UI

Professional legal-themed background

Smooth animations

Fully responsive design

ğŸ“¦ Tech Stack
Layer	Technology
Backend	Flask
LLM	Groq Llama-3.1-8B Instant
RAG	LangChain
Embeddings	HuggingFace Sentence Transformers
Vector DB	ChromaDB
PDF Extraction	PyPDF2
Frontend	HTML, CSS, JavaScript
Deployment-ready	Yes
ğŸ“‚ Project Structure
legal-search-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html
    â”œâ”€â”€ style.css
    â”œâ”€â”€ script.js
    â””â”€â”€ images/
        â””â”€â”€ legal.webp

ğŸ”§ Installation & Setup
1ï¸âƒ£ Install Dependencies

Inside the backend folder:

cd backend
pip install -r requirements.txt

ğŸ“„ requirements.txt
flask
flask-cors
python-dotenv
PyPDF2
langchain
langchain-community
langchain-text-splitters
sentence-transformers
chromadb
langchain-groq
langchain-huggingface

2ï¸âƒ£ Add Groq API Key

Create a .env file:

GROQ_API_KEY=your_groq_key_here


Get your key:
ğŸ”— https://console.groq.com/keys

3ï¸âƒ£ Start the Flask Server
python app.py


Server URL:

http://localhost:8000


This serves both backend + frontend.

ğŸ§  How the System Works

User uploads PDF

Backend extracts text using PyPDF2

Text is split into meaningful chunks

Embeddings are generated using HuggingFace

Stored temporarily in ChromaDB

User asks a question

Best-matching PDF chunks are retrieved

Groq Llama-3.1 model generates a succinct 2-line answer

ğŸ’¬ Example Usage

After uploading a â€œBudget Speech PDFâ€, ask:

What is the Centre of Excellence in AI for Education?


Or for a legal act:

Define the punishment for cyber fraud in this act.

ğŸ“¸ UI Preview (Optional)

Add your screenshot here:

![UI Preview](frontend/images/screenshot.png)

âš  Limitations

Only single-PDF querying at a time

Does not store PDFs permanently

Responses may not be legally verified

Does not highlight source text (can be added later)

ğŸš€ Possible Enhancements

I can generate any of these for you:

Multi-PDF library with selection

Citation highlighting

Chat history with memory

JWT login

Deployment Dockerfile

Dark/Light theme switch

Azure/AWS/GCP deployment guides

Just ask anytime!

ğŸ‘¤ Author

Developed by Shreyash
